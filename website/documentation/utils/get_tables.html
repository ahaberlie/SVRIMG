<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.8.4" />
<title>svrimg.utils.get_tables API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js" integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>svrimg.utils.get_tables</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from urllib.request import urlopen
from dateutil.parser import parse
import datetime
import os
import re
import numpy as np 
from urllib.error import HTTPError
import pandas as pd
import xarray as xr
import glob
from datetime import timedelta, datetime


def _create_unid(x, haz_type=&#34;&#34;):
    r&#34;&#34;&#34;Creates a unique id for each svrgis report.
    
    Parameters
    ----------
    x: Series
        A single row from a pandas DataFrame
    haz_type: str
        Optional additional identifier to add to unid. Default is &#34;&#34;.     
        
    Returns
    -------
    unid: str
        A unique id based on the information in a given pandas DataFrame row.
    &#34;&#34;&#34;  

    unid = &#34;{}{:02d}{:02d}{:02d}{:02d}z{:09d}_{}&#34;
    unid = unid.format(x[&#39;date_utc&#39;].year, x[&#39;date_utc&#39;].month, 
                       x[&#39;date_utc&#39;].day, x[&#39;date_utc&#39;].hour,
                       x[&#39;date_utc&#39;].minute, x[&#39;om&#39;], haz_type)                                         
    return unid   

def _create_dtime(x, UTC):
    r&#34;&#34;&#34;Generates datetimes from given DataFrame row columns date
    and time. If UTC=True, add 6 hours to this time.
    
    Parameters
    ----------
    x: Series
        A single row from a pandas DataFrame
    UTC: str
        If true, add 6 hours to the dtime.  
        Note: This only works with CST.     
        
    Returns
    -------
    unid: str
        A unique id based on the information in a given pandas DataFrame row.
    &#34;&#34;&#34;  

    dstr = &#34;{}-{}&#34;.format(x[&#39;date&#39;], x[&#39;time&#39;])
    dtime = parse(dstr)
    
    if UTC:             
        dtime += timedelta(hours=6)
    
    return dtime     

def _create_svrgis_table(in_name, out_name, haz_type, data_dir=&#34;../data/csvs&#34;, 
                         start_year=1996, end_year=2017, 
                         UTC=True):
    r&#34;&#34;&#34;Opens a given svrgis table from data_dir + in_name and returns a pandas
    DataFrame. If the table is already created, nothing will happe. Otherwise,
    it saves data_dir + out_name. This function assumes that &#39;data_dir&#39; exists.
    
    NOTE: If UTC is true, all report times are incremented by 6 hours. This
    is because SPC stores the dates as central standard time (CST) for every 
    day of the year.
    
    Parameters
    ----------
    in_name: str
        Name of original svrgis csv file that you downloaded from SPC.
    out_name: str
        Name of output csv file.   
    haz_type: str
        Optionally add this string to the end of the unid.         
    data_dir: str
        Location where the original svrgis csv file is and where the 
        new file will be saved. Default is &#34;../data/csvs/&#34;
    start_year: int
        First year from which to return data. Default is 1996.
    end_year: int
        Last year from which to return data. Default is 2017.
    time_format: str.
        Format in which to convert the report date. 
        Default is &#39;%Y-%m-%d-%H:%M:%S&#39;.
    UTC: bool.
        Whether or not to convert the svrgis time (CST) to UTC.
        Default is True.
        
    Returns
    -------
    td: DataFrame
        A pandas DataFrame containing the formatted svrgis data.
    &#34;&#34;&#34;  

    out_filename = &#34;{}/{}&#34;.format(data_dir, out_name)
    in_filename = &#34;{}/{}&#34;.format(data_dir, in_name)
    
    if os.path.exists(out_filename):
        print(&#34;File exists!&#34;, out_filename)
        
    else:
        td = pd.read_csv(in_filename)
        td[&#39;CST_date&#39;] = td[&#39;date&#39;]
        td[&#39;CST_time&#39;] = td[&#39;time&#39;]
        td[&#39;date_utc&#39;] = td.apply(lambda x: _create_dtime(x, UTC), axis=1)
        td = td.drop([&#39;date&#39;, &#39;time&#39;, &#39;yr&#39;, &#39;mo&#39;, &#39;dy&#39;], axis=1)
        td[&#39;yr&#39;] = td[&#39;date_utc&#39;].dt.year
        td[&#39;mo&#39;] = td[&#39;date_utc&#39;].dt.month
        td[&#39;dy&#39;] = td[&#39;date_utc&#39;].dt.day
        td[&#39;hr&#39;] = td[&#39;date_utc&#39;].dt.hour
        td = td[(td.yr &gt;= start_year) &amp; (td.yr &lt;= end_year)]
        td[&#39;uid&#39;] = td.apply(lambda x: _create_unid(x, haz_type), axis=1)
        td = td.set_index(&#39;uid&#39;)
        td.to_csv(out_filename)
        return td

def _create_index_table(out_name, haz_type, data_dir=&#34;../data/csv&#34;, 
                       url=&#34;http://svrimg.org/data/&#34;, start_year=1996, 
                       end_year=2017):
    r&#34;&#34;&#34;Attempts to download and concatenate monthly tables from svrimg for
    a given hazard type.  If the file doesn&#39;t exist, saves result out_name 
    in data_dir.  Otherwise, just returns DataFrame from existing file.
    
    Parameters
    ----------
    out_name: str
        Name of output csv file.     
    haz_type: str
        Optionally add this string to the end of the unid.
    data_dir: str
        Location where the original svrgis csv file is and where the 
        new file will be saved. Default is &#34;../data/csvs&#34;
    url: str
        Base url directory where the table data is located. 
        Default is &#34;http://svrimg.org/data/&#34;.
    start_year: int
        First year from which to return data. Default is 1996.
    end_year: int
        Last year from which to return data. Default is 2017.
        
    Returns
    -------
    td: DataFrame
        A pandas DataFrame containing the formatted svrimg index data.
    &#34;&#34;&#34;   
    
    out_filename = &#34;{}/{}&#34;.format(data_dir, out_name)
    
    if not os.path.exists(out_filename):
    
        return pd.read_csv(out_filename, index_col=&#39;unid&#39;)

    else:
        csvs = []
        
        for year in range(start_year, end_year+1):
        
            for month in range(1, 13):
                csv_name = &#34;report_box_indexer_{:02d}.csv&#34;.format(month)
                file_url = &#34;{}/{}/{}/{}&#34;.format(url, haz_type, 
                                                year, csv_name)
                tmp_csv = pd.read_csv(file_url, index_col=&#39;unid&#39;)
                csvs.append(tmp_csv)
                
        csvs = pd.concat(csvs)
        csvs.to_csv(out_filename)
        
        return csvs

def get_table(which, haz_type, data_dir=&#34;../data/csv&#34;, 
              url=&#34;http://svrimg.org/data/&#34;):
    r&#34;&#34;&#34;Downloads svrimg index or svrgis report table from the given url 
    and returns a pandas DataFrame. If the table is already downloaded, 
    it simply returns a pandas DataFrame. This assumes that &#39;data_dir&#39; 
    exists.
    
    Parameters
    ----------
    which: str
        Either &#39;svrimg&#39; for image indexes or &#39;svrgis&#39; for report attributes. 
    haz_type: str
        Identify what hazard key to request. Expecting &#39;tor&#39;, &#39;hail&#39;, 
        or &#39;wind&#39;.  
    data_dir: str
        Base directory in which to save the csv file. Default is 
        &#34;../data/csv/&#34;.
    url: str
        Base url directory where the table data is located. 
        Default is &#34;http://svrimg.org/data/&#34;.
        
    Returns
    -------
    table_data: DataFrame
        A pandas DataFrame containing svrimg index information.
    &#34;&#34;&#34;               

    if which == &#39;svrimg&#39;:
        csv_name = &#34;96-17_{}_utc_svrimg_index.csv&#34;.format(haz_type)
        
    elif which == &#39;svrgis&#39;:
        csv_name = &#34;96-17_{}_utc_gridrad.csv&#34;.format(haz_type)
        
    else:
        raise ValueError(&#34;Expected &#39;svrimg&#39; or &#39;svrgis&#39;, not {}.&#34;.format(which))
        
    file_url = &#34;{}/{}/{}&#34;.format(url, haz_type, csv_name)
    file_name = &#34;{}/{}&#34;.format(data_dir, fname)

    if not os.path.exists(file_name):
        tmp_csv = pd.read_csv(file_url, index_col=&#39;unid&#39;)
        tmp_csv.to_csv(file_name)

        return tmp_csv
        
    else:

        return pd.read_csv(file_name, index_col=&#39;unid&#39;)          
        
def get_pred_tables(data_dir, url=&#34;http://svrimg.org/data/&#34;, example=True, 
                    default_name=&#34;*_Table_*.csv&#34;, csv_name=&#34;eg_classes_96-17&#34;,
                    remove_first_row=False):
    r&#34;&#34;&#34;Either downloads example predictions if &#39;example&#39; is true, or combines your prediction
    tables in &#39;data_dir&#39; into one table using the default naming format of 
    &#39;*_Table_*.csv&#39; or whatever is passed into default_name. This will
    attempt to grab every year from 1996 - 2017, but will not fail if a year is missing. 
    By default, the first row in every year&#39;s table is example data on svrimg.org, and 
    it can be removed as long as &#39;remove_first_row&#39; is True. By default, if there is a 
    repeated UNID, the last one is kept.  The theory here is that if you accidentally 
    clicked something, you would go back and fix it.  Thus, the nth time is likely 
    more accurate.
    
    Parameters
    ----------
    data_dir: str
        Base directory in which to save the csv file.
    url: str
        Base url directory where the table data is located. 
        Default is &#34;http://svrimg.org/data/&#34;.
    example: bool
        If True, download example data.  If false, look for local 
        yearly tables. Default is True.
    default_name: str
        Naming format for local csv files. Stars are used as wildcards.
        Default is &#39;*_Table_*.csv&#39;.
    csv_name: str
        Default name of new csv file containing classifications.
    remove_first_row: bool
        Removes first row from each year of local table data if True, ignores 
        first row if false. Default is False.   
        
    Returns
    -------
    csv: DataFrame
        A pandas DataFrame of UNIDs and their predictions.
    &#34;&#34;&#34; 
 
    if example:
        if not os.path.exists(&#34;{}/{}.csv&#34;.format(data_dir, csv_name)):
            _url = url + &#34;sample_classifications_96-17.csv&#34;
            c = pd.read_csv(_url, index_col=&#39;UNID&#39;)
            c.to_csv(&#34;{}/{}.csv&#34;.format(data_dir, csv_name))
    else:
        csvs = []
        for fname in glob.glob(data_dir + &#34;*_Table_*.csv&#34;):
        
            print(&#34;Reading&#34;, fname)
            
            a = pd.read_csv(fname)
            a = a.drop(0)
            a = a.drop_duplicates(subset=[&#34;UNID&#34;], keep=&#39;last&#39;)
            a = a.set_index(&#34;UNID&#34;)
            csvs.append(a)
        csvs = pd.concat(csvs)
        csvs.to_csv(&#34;{}/{}.csv&#34;.format(data_dir, csv_name))
            
    return pd.read_csv(&#34;{}/{}.csv&#34;.format(data_dir, csv_name), index_col=&#39;UNID&#39;)

def get_geog(data_dir, url=&#34;http://svrimg.org/maps/&#34;):
    r&#34;&#34;&#34;Downloads svrimg geography netcdf file from the given url and returns
    an xarray dataset. If the netcdf file is already downloaded, it simply 
    returns an xarray dataset.  This assumes that &#39;data_dir&#39; exists.
    
    Parameters
    ----------
    data_dir: str
        Base directory in which to save the csv file.
    url: str
        Base url directory where the table data is located. 
        Default is &#34;http://svrimg.org/maps/&#34;.
  
    Returns
    -------
    geog: dataset
        An xarray dataset representation of the svrimg geography grid.
    &#34;&#34;&#34;  

    if not os.path.exists(&#34;{}/svrimg_geog.nc&#34;.format(data_dir)):
        
        _url = url + &#34;svrimg_geog.nc&#34;
        
        img = urlopen(_url)

        with open(&#34;{}/svrimg_geog.nc&#34;.format(data_dir), &#34;wb&#34;) as file:
            file.write(img.read())
        
        return xr.open_dataset(&#34;{}/svrimg_geog.nc&#34;.format(data_dir))
    else:
        #print(&#34;{}/svrimg_geog.nc&#34;.format(data_dir), &#34;is already downloaded&#34;)
        return xr.open_dataset(&#34;{}/svrimg_geog.nc&#34;.format(data_dir))
        </code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="svrimg.utils.get_tables.get_geog"><code class="name flex">
<span>def <span class="ident">get_geog</span></span>(<span>data_dir, url='http://svrimg.org/maps/')</span>
</code></dt>
<dd>
<div class="desc"><p>Downloads svrimg geography netcdf file from the given url and returns
an xarray dataset. If the netcdf file is already downloaded, it simply
returns an xarray dataset.
This assumes that 'data_dir' exists.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>data_dir</code></strong> :&ensp;<code>str</code></dt>
<dd>Base directory in which to save the csv file.</dd>
<dt><strong><code>url</code></strong> :&ensp;<code>str</code></dt>
<dd>Base url directory where the table data is located.
Default is "http://svrimg.org/maps/".</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>geog</code></strong> :&ensp;<code>dataset</code></dt>
<dd>An xarray dataset representation of the svrimg geography grid.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_geog(data_dir, url=&#34;http://svrimg.org/maps/&#34;):
    r&#34;&#34;&#34;Downloads svrimg geography netcdf file from the given url and returns
    an xarray dataset. If the netcdf file is already downloaded, it simply 
    returns an xarray dataset.  This assumes that &#39;data_dir&#39; exists.
    
    Parameters
    ----------
    data_dir: str
        Base directory in which to save the csv file.
    url: str
        Base url directory where the table data is located. 
        Default is &#34;http://svrimg.org/maps/&#34;.
  
    Returns
    -------
    geog: dataset
        An xarray dataset representation of the svrimg geography grid.
    &#34;&#34;&#34;  

    if not os.path.exists(&#34;{}/svrimg_geog.nc&#34;.format(data_dir)):
        
        _url = url + &#34;svrimg_geog.nc&#34;
        
        img = urlopen(_url)

        with open(&#34;{}/svrimg_geog.nc&#34;.format(data_dir), &#34;wb&#34;) as file:
            file.write(img.read())
        
        return xr.open_dataset(&#34;{}/svrimg_geog.nc&#34;.format(data_dir))
    else:
        #print(&#34;{}/svrimg_geog.nc&#34;.format(data_dir), &#34;is already downloaded&#34;)
        return xr.open_dataset(&#34;{}/svrimg_geog.nc&#34;.format(data_dir))</code></pre>
</details>
</dd>
<dt id="svrimg.utils.get_tables.get_pred_tables"><code class="name flex">
<span>def <span class="ident">get_pred_tables</span></span>(<span>data_dir, url='http://svrimg.org/data/', example=True, default_name='*_Table_*.csv', csv_name='eg_classes_96-17', remove_first_row=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Either downloads example predictions if 'example' is true, or combines your prediction
tables in 'data_dir' into one table using the default naming format of
'<em><em>Table</em></em>.csv' or whatever is passed into default_name. This will
attempt to grab every year from 1996 - 2017, but will not fail if a year is missing.
By default, the first row in every year's table is example data on svrimg.org, and
it can be removed as long as 'remove_first_row' is True. By default, if there is a
repeated UNID, the last one is kept.
The theory here is that if you accidentally
clicked something, you would go back and fix it.
Thus, the nth time is likely
more accurate.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>data_dir</code></strong> :&ensp;<code>str</code></dt>
<dd>Base directory in which to save the csv file.</dd>
<dt><strong><code>url</code></strong> :&ensp;<code>str</code></dt>
<dd>Base url directory where the table data is located.
Default is "http://svrimg.org/data/".</dd>
<dt><strong><code>example</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, download example data.
If false, look for local
yearly tables. Default is True.</dd>
<dt><strong><code>default_name</code></strong> :&ensp;<code>str</code></dt>
<dd>Naming format for local csv files. Stars are used as wildcards.
Default is '<em><em>Table</em></em>.csv'.</dd>
<dt><strong><code>csv_name</code></strong> :&ensp;<code>str</code></dt>
<dd>Default name of new csv file containing classifications.</dd>
<dt><strong><code>remove_first_row</code></strong> :&ensp;<code>bool</code></dt>
<dd>Removes first row from each year of local table data if True, ignores
first row if false. Default is False.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>csv</code></strong> :&ensp;<code>DataFrame</code></dt>
<dd>A pandas DataFrame of UNIDs and their predictions.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_pred_tables(data_dir, url=&#34;http://svrimg.org/data/&#34;, example=True, 
                    default_name=&#34;*_Table_*.csv&#34;, csv_name=&#34;eg_classes_96-17&#34;,
                    remove_first_row=False):
    r&#34;&#34;&#34;Either downloads example predictions if &#39;example&#39; is true, or combines your prediction
    tables in &#39;data_dir&#39; into one table using the default naming format of 
    &#39;*_Table_*.csv&#39; or whatever is passed into default_name. This will
    attempt to grab every year from 1996 - 2017, but will not fail if a year is missing. 
    By default, the first row in every year&#39;s table is example data on svrimg.org, and 
    it can be removed as long as &#39;remove_first_row&#39; is True. By default, if there is a 
    repeated UNID, the last one is kept.  The theory here is that if you accidentally 
    clicked something, you would go back and fix it.  Thus, the nth time is likely 
    more accurate.
    
    Parameters
    ----------
    data_dir: str
        Base directory in which to save the csv file.
    url: str
        Base url directory where the table data is located. 
        Default is &#34;http://svrimg.org/data/&#34;.
    example: bool
        If True, download example data.  If false, look for local 
        yearly tables. Default is True.
    default_name: str
        Naming format for local csv files. Stars are used as wildcards.
        Default is &#39;*_Table_*.csv&#39;.
    csv_name: str
        Default name of new csv file containing classifications.
    remove_first_row: bool
        Removes first row from each year of local table data if True, ignores 
        first row if false. Default is False.   
        
    Returns
    -------
    csv: DataFrame
        A pandas DataFrame of UNIDs and their predictions.
    &#34;&#34;&#34; 
 
    if example:
        if not os.path.exists(&#34;{}/{}.csv&#34;.format(data_dir, csv_name)):
            _url = url + &#34;sample_classifications_96-17.csv&#34;
            c = pd.read_csv(_url, index_col=&#39;UNID&#39;)
            c.to_csv(&#34;{}/{}.csv&#34;.format(data_dir, csv_name))
    else:
        csvs = []
        for fname in glob.glob(data_dir + &#34;*_Table_*.csv&#34;):
        
            print(&#34;Reading&#34;, fname)
            
            a = pd.read_csv(fname)
            a = a.drop(0)
            a = a.drop_duplicates(subset=[&#34;UNID&#34;], keep=&#39;last&#39;)
            a = a.set_index(&#34;UNID&#34;)
            csvs.append(a)
        csvs = pd.concat(csvs)
        csvs.to_csv(&#34;{}/{}.csv&#34;.format(data_dir, csv_name))
            
    return pd.read_csv(&#34;{}/{}.csv&#34;.format(data_dir, csv_name), index_col=&#39;UNID&#39;)</code></pre>
</details>
</dd>
<dt id="svrimg.utils.get_tables.get_table"><code class="name flex">
<span>def <span class="ident">get_table</span></span>(<span>which, haz_type, data_dir='../data/csv', url='http://svrimg.org/data/')</span>
</code></dt>
<dd>
<div class="desc"><p>Downloads svrimg index or svrgis report table from the given url
and returns a pandas DataFrame. If the table is already downloaded,
it simply returns a pandas DataFrame. This assumes that 'data_dir'
exists.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>which</code></strong> :&ensp;<code>str</code></dt>
<dd>Either 'svrimg' for image indexes or 'svrgis' for report attributes.</dd>
<dt><strong><code>haz_type</code></strong> :&ensp;<code>str</code></dt>
<dd>Identify what hazard key to request. Expecting 'tor', 'hail',
or 'wind'.</dd>
<dt><strong><code>data_dir</code></strong> :&ensp;<code>str</code></dt>
<dd>Base directory in which to save the csv file. Default is
"../data/csv/".</dd>
<dt><strong><code>url</code></strong> :&ensp;<code>str</code></dt>
<dd>Base url directory where the table data is located.
Default is "http://svrimg.org/data/".</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>table_data</code></strong> :&ensp;<code>DataFrame</code></dt>
<dd>A pandas DataFrame containing svrimg index information.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_table(which, haz_type, data_dir=&#34;../data/csv&#34;, 
              url=&#34;http://svrimg.org/data/&#34;):
    r&#34;&#34;&#34;Downloads svrimg index or svrgis report table from the given url 
    and returns a pandas DataFrame. If the table is already downloaded, 
    it simply returns a pandas DataFrame. This assumes that &#39;data_dir&#39; 
    exists.
    
    Parameters
    ----------
    which: str
        Either &#39;svrimg&#39; for image indexes or &#39;svrgis&#39; for report attributes. 
    haz_type: str
        Identify what hazard key to request. Expecting &#39;tor&#39;, &#39;hail&#39;, 
        or &#39;wind&#39;.  
    data_dir: str
        Base directory in which to save the csv file. Default is 
        &#34;../data/csv/&#34;.
    url: str
        Base url directory where the table data is located. 
        Default is &#34;http://svrimg.org/data/&#34;.
        
    Returns
    -------
    table_data: DataFrame
        A pandas DataFrame containing svrimg index information.
    &#34;&#34;&#34;               

    if which == &#39;svrimg&#39;:
        csv_name = &#34;96-17_{}_utc_svrimg_index.csv&#34;.format(haz_type)
        
    elif which == &#39;svrgis&#39;:
        csv_name = &#34;96-17_{}_utc_gridrad.csv&#34;.format(haz_type)
        
    else:
        raise ValueError(&#34;Expected &#39;svrimg&#39; or &#39;svrgis&#39;, not {}.&#34;.format(which))
        
    file_url = &#34;{}/{}/{}&#34;.format(url, haz_type, csv_name)
    file_name = &#34;{}/{}&#34;.format(data_dir, fname)

    if not os.path.exists(file_name):
        tmp_csv = pd.read_csv(file_url, index_col=&#39;unid&#39;)
        tmp_csv.to_csv(file_name)

        return tmp_csv
        
    else:

        return pd.read_csv(file_name, index_col=&#39;unid&#39;)          </code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="svrimg.utils" href="index.html">svrimg.utils</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="svrimg.utils.get_tables.get_geog" href="#svrimg.utils.get_tables.get_geog">get_geog</a></code></li>
<li><code><a title="svrimg.utils.get_tables.get_pred_tables" href="#svrimg.utils.get_tables.get_pred_tables">get_pred_tables</a></code></li>
<li><code><a title="svrimg.utils.get_tables.get_table" href="#svrimg.utils.get_tables.get_table">get_table</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.8.4</a>.</p>
</footer>
</body>
</html>